{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "myenv",
   "display_name": "myenv",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "d56d92bfe18e338fca9330cc11fbdc9ce2394a956871bac79070cba5d437aed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Student Answer -> Bert encoding\\\n",
    "Question -> BERT encoding ------.->cross attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_abstract = \"\"\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers.\n",
    " Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers.\n",
    " As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. \n",
    "BERT is conceptually simple and empirically powerful. \n",
    "It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ans = \"Sky is red\"\n",
    "question = \"What is the colour of the sky?\"\n",
    "reference_ans =\"Sky appears blue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBertEncoding(paragraph):\n",
    "        sentences = paragraph.split('.')\n",
    "        bert_embedding = BertEmbedding()\n",
    "        result = bert_embedding(sentences)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = getBertEncoding(student_ans)\n",
    "Q = getBertEncoding(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_values = K[0][1]\n",
    "Q_values = Q[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_values = np.array(K_values)\n",
    "Q_values = np.array(Q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.from_numpy(K_values)\n",
    "Q = torch.from_numpy(Q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention = attention(Q,K,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7137, 0.1191, 0.1672],\n",
       "        [0.0628, 0.8501, 0.0871],\n",
       "        [0.1534, 0.6523, 0.1942],\n",
       "        [0.2714, 0.3641, 0.3644],\n",
       "        [0.1581, 0.6745, 0.1674],\n",
       "        [0.1706, 0.6694, 0.1599],\n",
       "        [0.5924, 0.2356, 0.1720],\n",
       "        [0.1272, 0.2982, 0.5746]])"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "K_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self,inp_dim,hid_dim,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.inp_dim = inp_dim\n",
    "        self.hid_sim = hid_dim\n",
    "        self.hidden = nn.Linear(inp_dim,hid_dim)\n",
    "        self.output = nn.Linear(hid_dim,inp_dim)\n",
    "        self.relu = nn.ReLU\n",
    "        self.dropout = nn.Dropout\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,Value,Query,attentionBlock,feedForwardBlock,normBlock):\n",
    "        super().__init__()\n",
    "        self.value = Value\n",
    "        self.query = Query\n",
    "        self.attentionBlock = attentionBlock\n",
    "        self.feedForwardBlock = feedForwardBlock\n",
    "        self.normBlock = normBlock\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        att = self.attentionBlock(x)\n",
    "        x = self.normBlock(att,x)\n",
    "        ff = lambda(x, self.feedForwardBlock(x))\n",
    "        x = normBlock(ff)\n",
    "\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModule(nn.Module):\n",
    "    def __init__(self,Question,Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepresentationModule(nn.Module):\n",
    "    def __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn = nn.MultiheadAttention(embed_dim = 768, num_heads=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Value = K.reshape(3,1,768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = Q.reshape(8,1,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.5666,  0.0905, -0.3259,  ...,  0.1991,  0.3866,  0.0199]],\n",
       "\n",
       "        [[ 0.2259,  0.1880,  0.2643,  ..., -0.1996,  0.0378,  0.6731]],\n",
       "\n",
       "        [[ 0.4941, -0.0662,  0.1847,  ...,  0.0330, -0.1765,  0.4608]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4937,  0.1258,  0.0544,  ..., -0.1227,  0.0570, -0.1065]],\n",
       "\n",
       "        [[ 0.8392,  0.2743, -0.0246,  ...,  0.1315,  0.3748, -0.1369]],\n",
       "\n",
       "        [[-0.0101,  0.0074, -0.9819,  ...,  0.0519,  0.2797, -0.2009]]])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out,att =multihead_attn(key =Value,value = Value,query = Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.0201,  0.0883,  0.0876,  ...,  0.2936,  0.1124, -0.2299]],\n",
       "\n",
       "        [[ 0.0235,  0.0832,  0.0853,  ...,  0.3003,  0.1076, -0.2377]],\n",
       "\n",
       "        [[ 0.0253,  0.0837,  0.0876,  ...,  0.3009,  0.1112, -0.2433]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0266,  0.0802,  0.0843,  ...,  0.3021,  0.1068, -0.2465]],\n",
       "\n",
       "        [[ 0.0245,  0.0842,  0.0832,  ...,  0.2978,  0.1063, -0.2371]],\n",
       "\n",
       "        [[ 0.0246,  0.0870,  0.0877,  ...,  0.3002,  0.1140, -0.2309]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}