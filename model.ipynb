{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Student Answer -> Bert encoding\\\n",
    "Question -> BERT encoding ------.->cross attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model can be created using the makeModel function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from bert_embedding import BertEmbedding\r\n",
    "from torch import nn\r\n",
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.autograd import Variable\r\n",
    "import numpy as np\r\n",
    "import copy\r\n",
    "import math\r\n",
    "import time\r\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:46:50.450825Z",
     "start_time": "2021-08-19T05:46:40.301218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "from transformers import BertTokenizer, BertModel\r\n",
    "\r\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\r\n",
    "import logging\r\n",
    "#logging.basicConfig(level=logging.INFO)\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# % matplotlib inline\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "class BertEmbedding(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(BertEmbedding, self).__init__()\r\n",
    "        # Load pre-trained model tokenizer (vocabulary)\r\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased',\r\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\r\n",
    "                                  )\r\n",
    "        # Put the model in \"evaluation\" mode, meaning feed-forward operation.\r\n",
    "        self.model.eval()\r\n",
    "\r\n",
    "    def getEmbeddings(self,text):\r\n",
    "      tokens_tensor,segments_tensor = self.TextPreprocessing(text)\r\n",
    "      embeddings = self.generateEmbedding(tokens_tensor,segments_tensor)\r\n",
    "      return embeddings\r\n",
    "\r\n",
    "    def TextPreprocessing(self,text):\r\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\r\n",
    "        # Tokenize our sentence with the BERT tokenizer.\r\n",
    "        tokenized_text = self.tokenizer.tokenize(marked_text)\r\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\r\n",
    "        segments_ids = [1] * len(tokenized_text)\r\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\r\n",
    "        segments_tensors = torch.tensor([segments_ids])\r\n",
    "        return tokens_tensor,segments_tensors\r\n",
    "    \r\n",
    "    def generateEmbedding(self,tokens_tensor,segments_tensor):\r\n",
    "        with torch.no_grad():\r\n",
    "            outputs = self.model(tokens_tensor, segments_tensor)\r\n",
    "            hidden_states = outputs[2]\r\n",
    "        tokens = torch.stack(hidden_states,dim=0)\r\n",
    "        tokens = tokens.permute(1,2,0,3)\r\n",
    "        final_val = tokens[:,1:-1,-2,:]\r\n",
    "        return final_val"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "bert_abstract = \"\"\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers.\r\n",
    " Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers.\r\n",
    " As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. \r\n",
    "BERT is conceptually simple and empirically powerful. \r\n",
    "It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.\"\"\""
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:46:50.466826Z",
     "start_time": "2021-08-19T05:46:50.457834Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "student_ans = \"Sky is red\"\r\n",
    "question = \"What is the colour of the sky?\"\r\n",
    "reference_ans =\"Sky appears blue\"\r\n",
    "full_marks = 3"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:46:50.527825Z",
     "start_time": "2021-08-19T05:46:50.481829Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def getBertEncoding(paragraph):\r\n",
    "        sentences = paragraph.split('.')\r\n",
    "        bert_embedding = BertEmbedding()\r\n",
    "        result = bert_embedding(sentences)\r\n",
    "        emb = torch.Tensor(result[0][1])\r\n",
    "        # emb = emb.reshape(emb.size()[0],1,emb.size()[-1])\r\n",
    "        emb = emb.unsqueeze(0)\r\n",
    "        return emb"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:46:50.574825Z",
     "start_time": "2021-08-19T05:46:50.533828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "res = getBertEncoding(student_ans)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:46:58.765268Z",
     "start_time": "2021-08-19T05:46:50.580833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "res.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:46:58.810266Z",
     "start_time": "2021-08-19T05:46:58.770267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "K= getBertEncoding(student_ans)\r\n",
    "Q = getBertEncoding(question)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.017189Z",
     "start_time": "2021-08-19T05:46:58.815266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "multihead_attn = nn.MultiheadAttention(embed_dim = 768, num_heads=3)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.123189Z",
     "start_time": "2021-08-19T05:47:10.023193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def clones(module, N):\r\n",
    "    \"Produce N identical layers.\"\r\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.155191Z",
     "start_time": "2021-08-19T05:47:10.134191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\r\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\r\n",
    "    d_k = query.size(-1)\r\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\r\n",
    "             / math.sqrt(d_k)\r\n",
    "    if mask is not None:\r\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\r\n",
    "    p_attn = F.softmax(scores, dim = -1)\r\n",
    "    if dropout is not None:\r\n",
    "        p_attn = dropout(p_attn)\r\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.186192Z",
     "start_time": "2021-08-19T05:47:10.166193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class MultiHeadedAttention(nn.Module):\r\n",
    "    \"Multi-headed Attention module\"\r\n",
    "    def __init__(self, h, d_model, dropout=0.1):\r\n",
    "        \"Take in model size and number of heads.\"\r\n",
    "        super(MultiHeadedAttention, self).__init__()\r\n",
    "        assert d_model % h == 0\r\n",
    "        # We assume d_v always equals d_k\r\n",
    "        self.d_k = d_model // h\r\n",
    "        self.h = h\r\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\r\n",
    "        self.attn = None\r\n",
    "        self.dropout = nn.Dropout(p=dropout)\r\n",
    "        \r\n",
    "    def forward(self, query, key, value, mask=None):\r\n",
    "        if mask is not None:\r\n",
    "            # Same mask applied to all h heads.\r\n",
    "            mask = mask.unsqueeze(1)\r\n",
    "        nbatches = query.size(0)\r\n",
    "        \r\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \r\n",
    "        query, key, value = \\\r\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\r\n",
    "             for l, x in zip(self.linears, (query, key, value))]\r\n",
    "        \r\n",
    "        # 2) Apply attention on all the projected vectors in batch. \r\n",
    "        x, self.attn = attention(query, key, value, mask=mask, \r\n",
    "                                 dropout=self.dropout)\r\n",
    "        \r\n",
    "        # 3) \"Concat\" using a view and apply a final linear. \r\n",
    "        x = x.transpose(1, 2).contiguous() \\\r\n",
    "             .view(nbatches, -1, self.h * self.d_k)\r\n",
    "        return self.linears[-1](x)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.248238Z",
     "start_time": "2021-08-19T05:47:10.194194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "m = MultiHeadedAttention(h = 6,d_model = 768)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.354777Z",
     "start_time": "2021-08-19T05:47:10.257194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class FeedForwardLayer(nn.Module):\r\n",
    "    \"Feedforward with 1 hidden layer\"\r\n",
    "    def __init__(self,inp_dim,hid_dim,dropout = 0.1):\r\n",
    "        super(FeedForwardLayer, self).__init__()\r\n",
    "        self.inp_dim = inp_dim\r\n",
    "        self.hid_dim = hid_dim\r\n",
    "        self.hidden = nn.Linear(inp_dim,hid_dim)\r\n",
    "        self.output = nn.Linear(hid_dim,inp_dim)\r\n",
    "        self.relu = F.relu\r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "    def forward(self,x):\r\n",
    "        x = self.hidden(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.dropout(x)\r\n",
    "        x = self.output(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.385263Z",
     "start_time": "2021-08-19T05:47:10.361269Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class LayerNorm(nn.Module):\r\n",
    "    \"Construct a layernorm module.\"\r\n",
    "    def __init__(self, features, eps=1e-6):\r\n",
    "        super(LayerNorm, self).__init__()\r\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\r\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\r\n",
    "        self.eps = eps\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        mean = x.mean(-1, keepdim=True)\r\n",
    "        std = x.std(-1, keepdim=True)\r\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.449263Z",
     "start_time": "2021-08-19T05:47:10.393265Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class SublayerConnection(nn.Module):\r\n",
    "    \"Apply residual connection to any sublayer with the same size.\"\r\n",
    "    def __init__(self, size, dropout=0.1):\r\n",
    "        super(SublayerConnection, self).__init__()\r\n",
    "        self.norm = LayerNorm(size)\r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "\r\n",
    "    def forward(self, x, sublayer):\r\n",
    "        \r\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\r\n",
    "        # return x + sublayer(self.norm(x))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.479265Z",
     "start_time": "2021-08-19T05:47:10.454287Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class EncoderBlock(nn.Module):\r\n",
    "    \"An Encoder block that find the connection between Answer and Question\"\r\n",
    "    def __init__(self,attentionBlock,feedForwardBlock,size,dropout = 0.1):\r\n",
    "        super(EncoderBlock,self).__init__()\r\n",
    "        self.attentionBlock = attentionBlock\r\n",
    "        self.feedForwardBlock = feedForwardBlock\r\n",
    "        self.sublayer = clones(SublayerConnection(size,dropout),2)\r\n",
    "        self.size = size\r\n",
    "\r\n",
    "    def forward(self,Query,Value):\r\n",
    "        x = self.sublayer[0](Query, lambda x: self.attentionBlock(query=x, value=Value, key=Value))\r\n",
    "        print(x.size())\r\n",
    "        return self.sublayer[1](x, self.feedForwardBlock)\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.527262Z",
     "start_time": "2021-08-19T05:47:10.485264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class EncoderModule(nn.Module):\r\n",
    "    \"Stacks of Encoder blocks\"\r\n",
    "    def __init__(self, EncoderLayer,N):\r\n",
    "        super(EncoderModule,self).__init__()\r\n",
    "        self.layers = clones(EncoderLayer,N)\r\n",
    "        self.norm = LayerNorm(EncoderLayer.size)\r\n",
    "    \r\n",
    "    def forward(self,Query,Value):\r\n",
    "        for layers in self.layers:\r\n",
    "            Query = layers(Query = Query,Value = Value)\r\n",
    "        return Query\r\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.542266Z",
     "start_time": "2021-08-19T05:47:10.533264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "class RepresentationModule(nn.Module):\r\n",
    "    \"Bottom layer that gives 2 representations: Reference answer Rep and Student answer Rep\"\r\n",
    "    def __init__(self,EncoderModule, embeddingLayer):\r\n",
    "        super(RepresentationModule,self).__init__()\r\n",
    "        self.EncoderModules = clones(EncoderModule,2)\r\n",
    "        self.embeddingLayer = embeddingLayer\r\n",
    "        #Get 2 clones of EncoderModule\r\n",
    "    def forward(self, Question, ReferenceAnswer, StudentAnswer):\r\n",
    "        Q = self.embeddingLayer.getEmbeddings(Question)\r\n",
    "        seconds = time.time()\r\n",
    "        StuAns = self.embeddingLayer.getEmbeddings(StudentAnswer)\r\n",
    "        RefAns = self.embeddingLayer.getEmbeddings(ReferenceAnswer)\r\n",
    "        print(time.time()-seconds)\r\n",
    "        studentAnsRep = self.EncoderModules[0](Q,StuAns)\r\n",
    "        RefAnsRep = self.EncoderModules[1](Q,RefAns)\r\n",
    "        print(time.time()-seconds)\r\n",
    "        return (studentAnsRep,RefAnsRep)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.574260Z",
     "start_time": "2021-08-19T05:47:10.550264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "class PositionalEncoding(nn.Module):\r\n",
    "    \"Implement the PE function.\"\r\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\r\n",
    "        super(PositionalEncoding, self).__init__()\r\n",
    "        self.dropout = nn.Dropout(p=dropout)\r\n",
    "        \r\n",
    "        # Compute the positional encodings once in log space.\r\n",
    "        pe = torch.zeros(max_len, d_model)\r\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\r\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\r\n",
    "                             -(math.log(10000.0) / d_model))\r\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\r\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\r\n",
    "        pe = pe.unsqueeze(0)\r\n",
    "        self.register_buffer('pe', pe)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        print(self.pe[:,:x.size(1)].size())\r\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \r\n",
    "                         requires_grad=False)\r\n",
    "        print(x.size())\r\n",
    "        return self.dropout(x)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.764784Z",
     "start_time": "2021-08-19T05:47:10.579263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "class FinalFeedForwardLayer(nn.Module):\r\n",
    "    def __init__(self,input_size):\r\n",
    "        super().__init__()\r\n",
    "        self.fc1 = nn.Linear(input_size,400)\r\n",
    "        self.fc2 = nn.Linear(400,20)\r\n",
    "        self.fc3 = nn.Linear(20,10)\r\n",
    "        self.fc4 = nn.Linear(10,1)\r\n",
    "    def forward(self, xb):\r\n",
    "        xb = F.relu(self.fc1(xb))\r\n",
    "        xb = F.relu(self.fc2(xb))\r\n",
    "        xb = F.relu(self.fc3(xb))\r\n",
    "        xb = F.sigmoid(self.fc4(xb))      # batch wise forwarding\r\n",
    "        return xb\r\n",
    "    \r\n",
    "    def training_step(self, batch):\r\n",
    "        inputs, targets = batch \r\n",
    "        # Generate predictions\r\n",
    "        out = self(inputs)         \r\n",
    "        # Calcuate loss\r\n",
    "        loss = F.l1_loss(out, targets)  # batch wise training step and loss\r\n",
    "        return loss\r\n",
    "    \r\n",
    "    def validation_step(self, batch):\r\n",
    "        inputs, targets = batch\r\n",
    "        # Generate predictions\r\n",
    "        out = self(inputs)\r\n",
    "        # Calculate loss\r\n",
    "        loss =F.l1_loss(out, targets)       # batch wise validation and loss    \r\n",
    "        return {'val_loss': loss.detach()}\r\n",
    "        \r\n",
    "    def validation_epoch_end(self, outputs):\r\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\r\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine val losses of all batches as average\r\n",
    "        return {'val_loss': epoch_loss.item()}\r\n",
    "    \r\n",
    "    def epoch_end(self, epoch, result, num_epochs):\r\n",
    "        # Print result every 20th epoch\r\n",
    "        if (epoch+1) % 100 == 0 or epoch == num_epochs-1:\r\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.796787Z",
     "start_time": "2021-08-19T05:47:10.769786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "class PrepLayer(nn.Module):\r\n",
    "        def __init__(self,positionalLayer,d_model,max_size):\r\n",
    "            super(PrepLayer,self).__init__()\r\n",
    "            self.borderLayer = torch.zeros(1,1,768)\r\n",
    "            self.d_model = d_model\r\n",
    "            self.max_size = max_size\r\n",
    "            self.positionalEncoding = positionalLayer\r\n",
    "        def forward(self,StudAns,RefAns):\r\n",
    "            RefAns = torch.add(RefAns,1)\r\n",
    "            FinalRep = torch.cat((StudAns,self.borderLayer),dim=1)\r\n",
    "            FinalRep = torch.cat((FinalRep,RefAns),dim = 1)\r\n",
    "            FinalRep = self.positionalEncoding(FinalRep)\r\n",
    "            FinalRep = FinalRep.flatten(start_dim=1, end_dim=2)\r\n",
    "            self.padValue = torch.zeros(1,self.d_model*self.max_size*2+1 - FinalRep.shape[1])\r\n",
    "            FinalRep = torch.cat((FinalRep,self.padValue),dim = 1)\r\n",
    "            return FinalRep"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.843821Z",
     "start_time": "2021-08-19T05:47:10.811786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "class GetMarks(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(GetMarks,self).__init__()\r\n",
    "    def forward(self,grade,full_marks):\r\n",
    "        return grade*full_marks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "class GradingModule(nn.Module):\r\n",
    "    \"Uses the Representations to compare and grade them\"\r\n",
    "    def __init__(self,prepLayer,d_model,max_size):\r\n",
    "        super(GradingModule,self).__init__()\r\n",
    "        self.max_size = max_size\r\n",
    "        self.d_model = d_model\r\n",
    "        self.prepLayer = prepLayer\r\n",
    "        self.feedForward = FinalFeedForwardLayer(self.d_model*self.max_size*2 + 1)\r\n",
    "        self.GetMarks = GetMarks()\r\n",
    "        \r\n",
    "    def forward(self,stu,ref,full_marks):\r\n",
    "        FinalRep = self.prepLayer(stu,ref)\r\n",
    "        grade = self.feedForward(FinalRep)\r\n",
    "        final_marks = self.GetMarks(grade,full_marks)\r\n",
    "        return final_marks\r\n",
    "        \r\n",
    "        \r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.873785Z",
     "start_time": "2021-08-19T05:47:10.851790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "class Upgrader(nn.Module):\r\n",
    "    def __init__(self,Representation_Module, Grading_Module):\r\n",
    "        super(Upgrader,self).__init__()\r\n",
    "        self.RepModule = Representation_Module\r\n",
    "        self.GradModule = Grading_Module\r\n",
    "    def forward(self, StudentAns,Question,RefAnswer,full_marks):\r\n",
    "        stu_rep,ref_rep = self.RepModule( StudentAns,Question,RefAnswer)\r\n",
    "        grad = self.GradModule(stu_rep,ref_rep,full_marks)\r\n",
    "        return grad"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.904784Z",
     "start_time": "2021-08-19T05:47:10.882785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def makeModel(emb_dim = 768,heads = 3,hid_lay_dim = 2304, N = 6,max_size = 100):\r\n",
    "    c = copy.deepcopy\r\n",
    "    attn = MultiHeadedAttention(h=6,d_model=emb_dim)\r\n",
    "    ff = FeedForwardLayer(emb_dim,hid_lay_dim)\r\n",
    "    embedding_layer = BertEmbedding()\r\n",
    "    positionalLayer = PositionalEncoding(d_model=emb_dim)\r\n",
    "    model = Upgrader(\r\n",
    "                RepresentationModule(\r\n",
    "                    EncoderModule( EncoderBlock( c(attn), c(ff), emb_dim), N),\r\n",
    "                    embedding_layer)\r\n",
    "                ,GradingModule(\r\n",
    "                    PrepLayer(d_model=emb_dim,positionalLayer=positionalLayer,max_size=max_size),\r\n",
    "                    d_model=emb_dim,\r\n",
    "                    max_size=max_size\r\n",
    "                ))\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:47:10.951790Z",
     "start_time": "2021-08-19T05:47:10.915788Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "    model = makeModel()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "student_ans = \"Sky is red\"\r\n",
    "question = \"What is the colour of the sky?\"\r\n",
    "reference_ans =\"Sky appears blue\"\r\n",
    "full_marks = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "model(student_ans,question,reference_ans,full_marks)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4714689254760742\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([1, 3, 768])\n",
      "torch.Size([1, 3, 1])\n",
      "1.8134639263153076\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "d:\\Adi\\work\\CLG\\Capstone\\Capstone\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'full_marks'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-03280c846a71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudent_ans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreference_ans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_marks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Adi\\work\\CLG\\Capstone\\Capstone\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-22a5e6bc1638>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, StudentAns, Question, RefAnswer, full_marks)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStudentAns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQuestion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRefAnswer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_marks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mstu_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref_rep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRepModule\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mStudentAns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQuestion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRefAnswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstu_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_marks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Adi\\work\\CLG\\Capstone\\Capstone\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-76580cc617b9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, stu, ref, full_marks)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mFinalRep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mgrade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFinalRep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mfinal_marks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetMarks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrade\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_marks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfinal_marks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Adi\\work\\CLG\\Capstone\\Capstone\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-6b0363a2c248>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, grade, full_marks)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGetMarks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrade\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_marks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrade\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfull_marks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_marks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'full_marks'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "metadata": {
   "interpreter": {
    "hash": "d56d92bfe18e338fca9330cc11fbdc9ce2394a956871bac79070cba5d437aed6"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "71px",
    "width": "176px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}